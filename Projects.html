<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title>Arezoo Alipanah [Personal Webpage]</title>
    <script async defer src="main.js"></script>
    <script async defer src="./sidebar.js"></script>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
    <link rel="stylesheet" href="style.css">

</head>
<body >
<header class="header">
    <button id="menu_btn" class="btn btn--icon">
        <i class="bi bi-list"></i>
    </button>
    <h1>
        Arezoo Alipanah
    </h1>
</header>
<div class="grapper">
    <aside class="sidebar">
        <ul class="menu">
            <li class="menu__item">
                <a class="menu__link " href="index.html">
                    <i class="bi-house-fill"></i>
                    home
                </a>
            </li>
            <li class="menu__item">
                <a class="menu__link" href="CV.html">
                    <i class="bi bi-file-earmark-person-fill"></i>
                    CV
                </a>
            </li>
            <li class="menu__item">
                <a class="menu__link" href="Certificates.html">
                    <i class="bi bi-award"></i>
                    Certificates
                </a>
            </li>

            <li class="menu__item">
                <a class="menu__link menu__link--active" href="Projects.html">
                    <i class="bi bi-gear"></i>
                    Projects
                </a>
            </li>

            <li class="menu__item">
                <a class="menu__link" href="Abstracts.html">
                    <i class="bi bi-journal-bookmark"></i>
                    Abstracts
                </a>
            </li>

            <li class="menu__item">
                <a class="menu__link" href="More.html">
                    <i class="bi bi-person-circle"></i>
                    More
                </a>
            </li>


            <li class="menu__item">
                <a class="menu__link menu__link" href="Gallery.html">
                    <i class="bi bi-images"></i>
                    Gallery
                </a>
            </li>

            <li class="menu__item">
                <a class="menu__link" href="index.html#contact">
                    <i class="bi bi-person-lines-fill"></i>
                    Contact
                </a>
            </li>
        </ul>
    </aside>

    <div class="main">

        <cite class="project--cite" >
            Recent Projects
        </cite>



        <div class="project">

            <p class="project--p">
                <cite class="project--cite" >
                    Building a Deep Q-Network for Training Atari 2600 VCS Breakout
                </cite><br><br>
                <img class="project--img" src="img/project9.JPG" > <br><br>
                In this project, a deep Q-network is implemented using experience replay and target networks to train a 2600 VCS Breakout Atari game.
                 The coding has been done both in Tensorflow and Pytorch frameworks.
                 At first, a preprocess on the input images is done, and they are cut to make the process easier with fewer amounts of data.
                 Then, a greyscale is added to the images to reduce the processing time for training.<br><br>
                 <img class="project--img" src="img/project5.JPG" > <br><br> 
                 A frame buffer is considered based on 
                 <a href="https://arxiv.org/pdf/1312.5602.pdf" target=_blank>this article</a>
                 to be used on the experience replay.<br>
                 The CNN network has four dense convolutional layers and one output layer for the Q values. 
                which would be called on every agent's step.
                <img class="project--img" src="img/project7.JPG" > <br><br>
                Using target networks as reference Q-values, Q-learning TD error is computed.<br><br>
                <img class="project--img" src="img/project8.JPG" > <br><br>
                 After that, using the Adam Optimizer, the agent has trained for about 75k steps. 
                 Finally, after reaching a reward of almost 13 or 14 per every life, the training is stopped. 
                Here you can see the result:
                <a href="https://youtu.be/C3tqwUvX8P8" target="_blank">
                    <i class="bi bi-youtube"></i>
                </a><br><br>
                <!--Here is the GitHub link of this project:
                <a href="https://github.com/ArezooAalipanah/RL_Examples/blob/main/week4_approx/dqn_atari_pytorch.ipynb" target="_blank">
                    <i class="bi bi-github"></i>
                </a>-->

            </p>
        </div>


        <div class="project">

            <p class="project--p">
                <cite class="project--cite" >
                    Building a Deep Reinforcement Learning with Advantage Actor-Critic for Atari Kung-Fu Master
                </cite><br><br>
                <img class="project--img" src="img/project10.JPG" > <br><br>
                This project is training an agent for playing Atari Kung-Fu Master gym environment with parallel Advantage Actor-Critic method.<br> 
                First, four grayscaled frames are stacked and cropped to make the agent interpret the object's velocity. <br>
                <img class="project--img" src="img/project11.JPG" > <br><br>
                Then, the agent is built with three convolutional neural layers containing 32 filters and the elu activation function,
                 followed by a final dense layer with 128 units.<br>
                 Finally, there are two outputs, one for the actor and one for the critic part, the actor has its units based on the number of actions in the game, 
                 and the critic is the value predicted which has one unit.  <br>
                 <img class="project--img" src="img/project12.JPG" > <br><br>
                 Then, the environment is trained to get the rewards.
                 The training process is done with ten different environments on parallel to make the training more stable.<br> 
                 For each of the environments, the agent tries to use this a3c algorithm to improve its rewards.<br>
                 After reaching a good reward, and a near-zero policy entropy, it is interpreted that the agent has learned the policy.
    
                Here you can see the result:
                <a href="https://youtu.be/A4EvvPbbHXw" target="_blank">
                    <i class="bi bi-youtube"></i>
                </a><br><br>
                <!--Here is the GitHub link of this project:
                <a href="https://github.com/ArezooAalipanah/RL_Examples/blob/main/week5_policy_based/practice_a3c2.ipynb" target="_blank">
                    <i class="bi bi-github"></i>
                </a>-->

            </p>
        </div>


        <div class="project">

            <p class="project--p">
                <cite class="project--cite" >
                    Translation of Hebrew words in English(g2p) with a policy-based reinforcement learning method
                </cite><br><br>
                Considering words as a sequence of letters, an encoder-decoder architecture is used in this project to convert Hebrew words to their English translations.<br> 
                After mapping strings to token ids and vice versa, the encoder reads words character by character and outputs code vector, 
                and the decoder takes that code vector and produces translations character by character. Here minimal Levenshtein distance is used.<br>
                It measures how many characters we need to add/remove/replace from model translation to make it perfect. <br>
                Reinforcement learning is employed in this project to translate the words with self-critical sequence training.<br><br>

                <img class="project--img" src="img/project3.png" > <br><br>
                <!--Here is the GitHub link of this project:
                <a href="https://github.com/ArezooAalipanah/RL_Examples/blob/main/week6_outro/seq2seq/practice_tf.ipynb" target="_blank">
                    <i class="bi bi-github"></i>
                </a>-->

            </p>
        </div>

        

        <div class="project">

            <p class="project--p">
                <cite class="project--cite" >
                    Deep Cross Entropy Method:
                </cite><br><br><br>

                The first part of this project is learning to control an inverted pendulum using cross entropy method on gym environment.<br><br>

                <img class="project--img" src="img/project4.png" > <br><br>

                The second part of the project is for the mountain climbing car to reach the goal on top of the mountain
                via deep cross entropy method. As it is pictured in the graph bellow you can see that the car learns
                the best policy and reaches the goal using this method.<br><br><br><br>

                <img class="project--img" src="img/project2.png" > <br><br>
                Here is the GitHub link of this project:
                <a href="https://github.com/ArezooAalipanah/RL_Examples/blob/main/week1_intro/deep_crossentropy_method.ipynb" target="_blank">
                    <i class="bi bi-github"></i>
                </a>
            </p>
        </div>

        <div class="project">
              
            <p class="project--p">
                <cite class="project--cite">
                    Building a web page like Google Keep
                </cite><br><br>
                This project was the Front-end development workshop's project held by "Made in Lobby 2021".
                The concepts covered were javascript, HTML, and CSS. I was an attendee in this workshop. This project has
                the aim of making a webpage like "Google Keep." To do so, first adding notes were distinguished using javascript,
                then some stylings were added like the ones in google keep itself. Here are some pictures of how this webpage would
                look like in different devices having different sizes.<br><br>
                This is how the webpage looked finally:<br>
                <img class="project--img" src="img/project1.JPG"><br><br>
                Here is the GitHub repository of this project:
                <a href="https://github.com/ArezooAalipanah/front_ws" target="_blank">
                    <i class="bi bi-github"></i>
                </a>

            </p>
        </div>

        <div class="project">

            <p class="project--p">
                <cite class="project--cite" >
                    The Brick Breaker Game by Python,
                    (CS106A project, Code in place 2020, C. Piech & M. Sahami)
                </cite><br><br>
                This is CS106A final project for code in place, Stanfor university;
                The main idea behind this project is to use Python merely to creat a game.
                Here is a demo of how the game works:
                <a href="https://compedu.stanford.edu/codeinplace/public/projects/0019.html">Stanford Code in Place Projects</a>
            </p>
        </div>

        <div class="project">

            <p class="project--p">

                Some of other projects:<br><br>


                <cite class="project--cite" >
                    Design and Implementation of an Object Avoidance and Path Planning Algorithm for TurtleBot3 in ROS,
                    (ROS & Gazebo training online course project, Maktabkhooneh)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                    3RPS Parallel Manipulator kinematics, dynamical modeling, and motion/force control by MSC Adams and Matlab,
                    (Parallel Robots course project, Prof. Hamid D. Taghirad)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                    Designing a Fuzzy Logic Controller for Car Parallel Parking by MATLAB Simulink,
                    (Fuzzy Logic and Fuzzy Artificial Neural Network Control course project, Prof. Ali Ghaffari)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                    AL5B Serial Manipulator kinematics, dynamical modeling, and motion/force and impedance control by MATLAB,
                    (Control in Robotics course project, Prof. S. A. A. Moosavian)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                    Designing a program for ordering car prices in a MySQL database, (Advanced Python online course,
                    Web scrapping project, Maktabkhooneh)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                Car Price Prediction via Linear Regression, SVM, KNN and ANN by MATLAB,
                (Machine Learning course project, Dr. Babak Nasersharif)
                </cite><br><br><br><br>

                <cite class="project--cite" >
                Deep Neural Network for Image Classification,
                (Neural Networks and Deep Learning online course project, Coursera, Andrew Ng)
                </cite><br>
            </p>
        </div>


    </div>
    <script> </script>
</div>
</body>
</html>